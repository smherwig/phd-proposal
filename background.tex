\section{Problem and Goals}
\label{sec:background}

\subsection{Applications}

I focus on two use cases that involve multiple parties cooperatively running
an application where the input of at least one party is confidential:
(1) outsourcing TLS-based applications to a third-party, and (2)
analyzing the private data of multiple parties.


\parhead{Outsourcing TLS applications}
%
I consider a company using a third-party, such as a cloud host or cloud
service, to operate an application server.
%
A common case is a company using a content delivery network (CDN) to
host their web content, and optionally manage their DNS and mail servers.
%
Virtually all of the most popular websites (and a very long tail
of unpopular websites) use one or more CDNs to help reliably host
their content~\cite{key-sharing}. 
%
Historically, CDNs have been thought of as a massive web
cache~\cite{cdn-on-demand}, but todayâ€™s CDNs play a critical role in achieving
the performance and security that the web relies on~\cite{securing-cdns}.
% TODO: additional sentence or phase



As a CDN requires the company's private TLS to key serve content over HTTPS,
the \emph{status quo} is for the company to share or otherwise entrust the CDN
with the application's private keys.
%
Indeed, CDNs have amassed the vast majority of private keys on the
web~\cite{key-sharing,when-https-meets-cdn}.
%
This has significant implications on the trust model of the PKI and the web
writ large, as the CDNs  can arbitrarily impersonate any of their customers.


\parhead{Collaborative Data Processing}
%
I assume a multi-party setting, where the parties agree on an analysis to be
performed, and the aggregate input for the analysis consists of the
confidential, local, datasets of each party.
% 
The parties themselves might be mutually distrustful, or may simply be
prevented by law from sharing their data.
%
The purpose of the analysis is to process the datasets to determine some
non-confidential result.
%
With federated databases, the result may be the cardinality of an intersection
across the datasets.
%
With federated learning, the result may be the global model parameters (such
as the weights of a deep neural network), derived from the aggregation of the
parameters from each party's locally-trained model.



% TODO: some small section about the security implications, or what we can't do
% today because we don't have the right tools.


\subsection{Goals}
At a high-level, our goal is to make hetergeneous trust a concern
of the application's run-time execution environment, rather than a concern of
the application developer.
%
I distill our overarching goal down to three specifics:

\begin{enumerate}
\item \textbf{Preserve confidentiality of private data:} The execution
environment \emph{must} maintain the confidentiality of the private keys and
private data sets of each party.
\item \textbf{Ensure data integrity:} The execution environment \emph{should}
    preserve the integrity of each party's data.
\item \textbf{Require minimal changes to existing applications:}
    The execution environment \emph{should} maintain the abstraction of a monolithic
application, and the transparency of the run-time's partitioning of the
application across trust domains.
%
configuration.
\end{enumerate}

% broader impact
If successful, I will not only improve the security and privacy of the
involved parties, but also enable more flexible application deployment options,
as well as support the development of new applictaions that leverage the
collective knowledge of private data sets while respecting the privacy of the
individuals represented in the data.

\subsection{Threat Model}

When I speak of trust, colloquially I  mean ``expect". 
%
In this setting, trust is an expectation that a party or application operates in
its stated purpose, and, in particular, does not purposefully leak private
data.
%
The goal of an adversary is to leak the private data of another party involved
in the computation.
%
I assume that a party trusts their software, and transitively, any software
written by a trusted party.
%
I assume that the parties trust the application; guaranteeing that an
\emph{untrusted}, arbitrary, application does not leak sensitive data is
difficult, as such guarantees would entail restricting the application.


I allow myself to assume several threat models.
%
The weakest threat model I assume is honest but curious: each party faithfully
executes the program, but may analyze their portion of the execution to try to
recover the private data of other principals.
%
The strongest threat model is a byzantine faulty adversary, where a party may
abuse the interface between their execution, and that of another party.
%
The Iago class of semantic attacks~\cite{iago-attacks}, which violate
tacit assumptions in inter-domain procedure calls---such as system calls,
enclave calls, or general RPCs---fall under this behavior.
%
In this model, parties must validate the execution state against expected
conditions during inter-domain transactions.


There are two additional assumptions which I sometimes consider that
influence system design.
%
The first is whether the application if bug-free, or whether is may, due to
programmer error, inadvertently leak data.
%
If I allow buggy applications, then the design must not only provide isolated
execution, but also a sandbox for information flow.
%
The second is whether the application is globally public, or whether some
portions are private and thus confidential to a party. 
%
For instance, in the scenario of a company outsourcing a web server to a CDN,
the CDN's web server may be proprietary.
%
In short, must the system handle private code in addition to private data.


Typical of other work in this area, I consider side-channels out of scope.
