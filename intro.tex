\section{Introduction}
\label{sec:intro}

Software is often written assuming monolithic trust assumptions, whereby
the user tacitly trusts both the software and the environment in which it runs.
%
This assumption is valid when the user, say an organization, develops the
software, owns the infrastructure, and administers all parts of the resultant
system.
%
However, the assumption no longer holds for service models that involve
distrustful parties.
%
A prime example is an organization that outsources its services to untrusted
third parties, such as content delivery networks and mail providers.
%
Outsourcing is an attractive way for an organization to reduce costs,
increase availabilty, or gain additional protections inherent to these hosting
environments.
%
Unfortunately, outsourcing poses a security tradeoff: the third party
providers that offer or deploy these services potentially gain access to
sensitive information about the organization and its clients.   
%
%Moreover, in cases where the organization abandons in-house services in favor
%of a provider's software suite, the organization may no longer have insight
%into what software is even implementing the service.


% TODO: maybe expand this paragraph a bit
%
% XXX: the problem is larger than just running trusted software on an untrusted
% host.

Running trusted applications with strong security and privacy guarantees on
untrusted third parties is a large and active area of research; it spans uses
of trusted hardware and functional encryption that seek to continue hosting
applications completely on third parties, to (re-)designing applications and
protocols so as to delegate trust, preserve privacy, or otherwise partition the
application's execution across trust boundaries and application integrity.
%
Unfortunately, this prior work either requires modifications to the
application, or has severe limits on the types of unmodified applications
supported.


% this is too specific
My thesis is:
\begin{displayquote}
    It is possible to run legacy application binaries with confidentiality and
    integrity guarantees that reflect the potentially multi-party trust model
    in which the application is deployed.
\end{displayquote}
% Running unmodified, legacy binaries that have monolithic trust assumptions in
% environments where such assumptions do not hold.  

% For instance, an organization to outsource their unmodified, legacy, services
% to an untrusted hosting provider, who may in fact provide the service itself,
% without leaking private data to the provider and with guarantees that the
% provider does not deviate from the service's expected behavior.


%The term \emph{multi-lateral trust model} means that the trust model may
%encompass the concerns of multiple parties.
%
The constraint of running unmodified, legacy services implies that the
enforcement of security, privacy, and correctness guarantees is the
responsibilty of the service's run-time execution environment. 
%
Since the execution environment is transparent to the application, the insight
is that it may be modified, partitioned, and distributed across domains of
varying trustworthiness, so as to reflect the security goals.
%
My approach is to modify the application's execution environment so that
parties can specify as policy their desired confidentiality and integrity
guarantees with respect to the application, with the execution environment
appling and enforcing the policy.


Several factors strongly influence the design of such an execution environment:
the presence of trusted hardware, the trust each party has in the application,
and the mechanisms for defining and enforcing trust boundaries.
%
In my preliminary work, \textbf{conclaves}, I assume the presence of Intel SGX hardware
enclaves and that the organization trusts the service.
%
Conclaves extends prior work on SGX-based library operating systems (libOS) by
extending a libOS to support a broader set of legacy services: namely,
multi-process, shared resource, applications.
%
My extensions result in a distributed system reminiscent of a microkernel,
where each kernel service (for instance, a filesystem or shared memory)
runs in a separate enclave and mediates that service’s shared resources
among the application's enclaved processes.
%
With conclaves, the trust policy is code-centric, as the parties specify which
processes comprise the system, as well as which processes may interact with one
another.


My proposed work, \textbf{codomains}, treats trusted hardware availability as a
policy concern.
%
Codomains maintain the source-level abstraction of a monolithic program, but
allow applications to dynamically switch execution to different domains—hosts
and enclaves—via language-neutral mechanisms.
%
Within a domain, the application may pin data to the domain or to a subset of
peer domain.
%



%
With Gemini, the trust policy is data-centric, as parties specify which data
must be isolated from other parties and how data may flow throughout the
system.


This proposal is organized as follows: in \S\ref{sec:background}, I describe
the problem setup, the threat model, and the system goals.
%
In \S\ref{sec:related}, I provide an overview of trusted execution
environments (TEEs), and techniques for running legacy applications
in TEEs.
%
I also describe techniques for data isolation and integrity that pre-date, or
are otherwise orthogonal to, TEEs.
%
In \S\ref{sec:conclaves-summary}, I summarize my preliminary work.
%
In \S\ref{sec:codomains-intro} I introduce the concept of codomains, as well as
a related concept of the coprocess, and in \S\ref{sec:codomains-design} sketch
their design.
%
I describe a set of evaluations for codomains in \S\ref{sec:codomains-eval}.
%
I conclude in \S\ref{sec:conclusion}.
