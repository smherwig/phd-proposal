\section{Introduction}
\label{sec:intro}

Software is often written assuming monolithic trust assumptions, whereby
the user tacitly trusts both the software and the environment in which it runs.
%
This assumption is valid when the user, say an organization, develops the
software, owns the infrastructure, and administers all parts of the resultant
system.
%
However, the assumption no longer holds for service models that involve
distrustful parties.
%
A prime example is an organization that outsources its services to untrusted
third parties, such as content delivery networks and mail providers.
%
Outsourcing is an attractive way for an organization to reduce costs,
increase availabilty, or gain additional protections inherent to these hosting
environments.
%
Unfortunately, outsourcing poses a security tradeoff: the third party
providers that offer or deploy these services potentially gain access to
sensitive information about the organization and its clients.   
%
Moreover, in cases where the organization abandons in-house services in favor
of a provider's software suite, the organization may no longer have insight
into what software is even implementing the service.


% TODO: maybe expand this paragraph a bit
%
% XXX: the problem is larger than just running trusted software on an untrusted
% host.
Running trusted applications with strong security and privacy guarantees on untrusted
third parties, and its dual, running untrusted applications within a
trusted environment, is a large and active area of research; it spans uses of
trusted hardware and functional encryption that seek to continue hosting
applications completely on third parties, to (re-)designing applications and
protocols so as to delegate trust, preserve privacy, or otherwise partition
the application's execution across trust boundaries.
%
Unfortunately, this prior work either requires modifications to the
application, or has severe limits on the types of unmodified applications
supported.


% this is too specific
My thesis is:
\begin{displayquote}
    It is possible to run legacy application binaries with confidentiality and
    integrity guarantees that reflect the potentially multi-lateral trust model
    in which the application is deployed.
\end{displayquote}
% Running unmodified, legacy binaries that have monolithic trust assumptions in
% environments where such assumptions do not hold.  

% For instance, an organization to outsource their unmodified, legacy, services
% to an untrusted hosting provider, who may in fact provide the service itself,
% without leaking private data to the provider and with guarantees that the
% provider does not deviate from the service's expected behavior.


The term \emph{multi-lateral trust model} means that the trust model may
encompass the concerns of multiple parties.
%
The constraint of running unmodified, legacy services implies that the
enforcement of such security, privacy, and correctness guarantees is the
responsibilty of the service's run-time execution environment. 
%
Since the execution environment is transparent to the application, the insight
is that it may be modified, partitioned, and distributed across domains of
varying trustworthiness, so as to reflect the security goals.


The design space is strongly influenced by several factors: the presence of
trusted hardware, the organization's trust in the application, and the
mechanisms for defining and enforcing trust boundaries.
%
In my preliminary work, \textbf{conclaves}, I assume the presence of Intel SGX hardware
enclaves and that the organization trusts the service.
%
Conclaves extends prior work on SGX-based library operating systems (libOS) by
extending a libOS to support a broader set of legacy services: namely,
multi-process, shared resource, applications.
%
My extensions result in a distributed system reminiscent of a microkernel,
where each kernel service (for instance, a filesystem or shared memory)
runs in a separate enclave and mediates that service’s shared resources
among the application’s enclaved processes---effectively a \textbf{con}tainer
of en\textbf{claves}.
%
With conclaves, the trust policy is code-centric, as the conclave owner
specifies which processes comprise the system, as well as which processes may
interact with one another.


My proposed work, \textbf{Gemini}, treats trusted hardware availability and
application trustworthiness as policy concerns.
%
Gemini is an execution environment that offers two complementary abstractions:
(1) \emph{distributed containers}, where organizations may pin sensitive data to
domains (such as a host) that they trust; a thread's execution migrates to the
trusted domain when computing with the sensitive data or any sensitive data
derived from it, and (2) \emph{policy monitors}---modules that an organization
may install in a trusted environment that enforce expected behavior of an
untrusted application.
%
A key feature of policy monitors is that the policies express a specification
for program correctness based on tracking information flows, which
the monitor enforces at run-time.
%
With Gemini, the trust-policy is data-centric, as a party specifies which data
must be isolated from other parties and how the data may flow within the
system.


This proposal is organized as follows:

