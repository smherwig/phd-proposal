\section{Codomains Design}
\label{sec:codomains-design}

My goal in this section is to explore the concept of codomains to arrive at an
application programming interface (API) for developing programs for such an
execution model.
%
The core features I need are pinning data to a domain and switching
(migrating) between domains, while the core challenges I face are providing
resource consistency and mechanism transparency.
%
I begin by introducing the coprocess abstraction, and then describe how we
implement codomains on top of coprocesses.


\subsection{Coprocesses}

%% definition
A \emph{coprocess} is a process to which a client process yields its
execution.
%
My interest with coprocesses is handling, in userspace, services requisite to
codomains: distributed shared memory, distributed fileystems, and the
checkpointing and restoring of the client process, while further enabling both
explicit and implicit yields to these services.
%
In these respects, a coprocess is similar to a library operating system, but
one that operates in an address space distinct from its client process: instead of
trapping directly to the kernel, the process traps to its coprocess, which may
either service the trap on its own, or forward the trap to the kernel.

%% TODO: sentence about why in userspace, or some tie-in to exokernels

%% suggest that the concept exists in narrow forms.
Coprocesses are not a novel idea: operating systems already partially expose the
concept through system calls like \texttt{ptrace} and
\texttt{userfaultfd}, which allow one process to control aspects of another,
and through runtime loading techniques such as \texttt{LD\_PRELOAD}, which
enable shims for proxying a process's library calls.
%
Part of my work is in exploring whether these existing facilities are
sufficient for my flavor of coprocesses, or whether I must develop additional
system calls for that purpose.


\parhead{Coprocess API}
%% Becoming a coprocess; attaching to
%
In Listing~\ref{lst:coproc-api}, I present the coprocess API\@.
%
The API design presents the coprocess as an ambient service to the process
(similar to the kernel), abstracting away any details of IPC between the
coprocess and process.
%
A process becomes a coprocess by calling \texttt{coproc\_create}, whose
argument is a unique pathname identifying the coprocess, and whose return value
is a socket-like descriptor for communicating with future client processes.
%
A client process attaches to a coprocess by calling \texttt{coproc\_set}, passing as an
argument the path representing the coprocess.
%
A process may have at most one coprocess, and a coprocess may service multiple
processes.
%
%A processes's coprocess, and the state of being a coprocess, are attributes
%within a process's control block.


%% Interaction between a process and coprocess
A process synchronously interacts with its coprocess through
\texttt{coproc\_call}; \texttt{coproc\_call} is to a coprocess as a system call
is to the kernel, and developers may implement application-specific messages
on top of this call.
%
A process may also synchronously invoke its coprocess through
\texttt{coproc\_raise}.
%
The semantic difference between \texttt{coproc\_raise} and
\texttt{coproc\_call} is that \texttt{coproc\_raise} does not return---the
process does not receive a return value and does not expect to resume
execution at the instruction following the call to \texttt{coproc\_raise}.
%
In these respects, \texttt{coproc\_raise} is analogous to the process raising
an exception.

\begin{lstlisting}[
    frame=single, 
    caption={Coprocess API},
    captionpos=b,
    label={lst:coproc-api},
]
int coproc_create(const char *path)
int coproc_set(const char *path)
int coproc_call(int msgtype, void *args, void *result)
void coproc_raise(void *args)
\end{lstlisting}


\parhead{Coprocess Events}
%
% TODO: whereas the coprocess API section describes the interface mostly
% from the process's perspective, now describe the types of messages a
% coprocess reads throught the socket decriptor thtat coproc_create returned.


\parhead{Coprocess Server}
% TODO: define and \emph{} coprocess server, since we use that term later with
% codomain.
%
Before delving into codomains, consider how switching execution between domains
would appear at the coprocess-level.
%
A process in domain A sets a coprocess and yields execution.
%
The coprocess checkpoints the process's thread and then makes a remote request
to a service in domain B\@.
%
B's service may either be a coprocess, or a service that executes a new
coprocess.
%
Regardless the service must also execute a stub program that first attaches to the
coprocess and then launches a loader that restores A's thread.
%
Any page faults during the restoration process trap to the coprocess on B,
which may request the page from the coprocess on A.


\subsection{Codomains}

I first introduce codomains programmatically with a two-party example in
Listing~\ref{lst:isolating-key} that isolates private key operations to a
single domain, \texttt{domain\_priv}; all other parts of the application
execute in the initial domain, \texttt{domain\_pub}.

\begin{lstlisting}[
    frame=single, 
    caption={Isolating a private key to a domain},
    captionpos=b,
    label={lst:isolating-key},
    numbers=left,
    numberstyle=\tiny,
    xleftmargin=2em,
    framexleftmargin=1.5em,
    ]
int domain_priv;
int domain_pub;
char *key;

load_key(path) {
    domain_pub = co_switch(domain_priv)
    key = read_file(path)
    co_pinmem(key)
    log(log_fd, "loading key (%s)", path)
    co_switch(domain_pub)
    return key;
}
 
sign(key, buf, buflen) {
     domain_pub = co_switch(domain_priv)
     signature = do_sign(key,buf)
     log(log_fd, "signed something");
     co_switch(domain_pub)
     return signature; 
 }

main(int argc, char *argv[]) {
    coproc_set("/srv/foo.coproc");
    domain_priv = co_attach(url, rspec)
    load_key(argv[1])
    sign(key, argv[2], strlen(argv[2]))
}
\end{lstlisting}


\texttt{domain\_pub} sets its coprocess on line 23, and then attaches to 
\texttt{domain\_priv} on line 24.
%
The \texttt{url} argument to \texttt{co\_attach} specifies the coprocess server
for \texttt{domain\_priv}, and \texttt{rspec} describes the resources (such as
filesystem, open descriptors, memory pages) that \texttt{domain\_pub} exports
to \texttt{domain\_priv}.
%
The return value of \texttt{co\_attach} is a descriptor for the attached
domain; the descriptor only has meaning to the coprocess, and is not present
in the process's kernel-level file descriptor table.


On line 25, the process calls \texttt{load\_key}, which then invokes
\texttt{co\_switch} to switch to \texttt{domain\_priv}.
%
\texttt{co\_switch} checkpoints the thread on \texttt{domain\_pub} and restore
the thread on \texttt{domain\_priv}.
%
\texttt{co\_switch} returns a descriptor representing the domain that
initiated the switch.


Within \texttt{load\_key}, \texttt{domain\_priv} pins the memory pages storing
the private key by invoking \texttt{co\_pinmem};
such pages are cloaked when executing in another
domain, and uncloaked when a thread executes in the caller's domain.
%
The \texttt{load\_key} and \texttt{sign}
functions perfectly encapsulate the key's use, and thus  \texttt{co\_switch}
simply ``wraps" their invocation.


\parhead{Codomain API}
%
In Listing~\ref{lst:codomain-api}, I present the codomain API\@.
%
Since I covered \texttt{co\_attach} and \texttt{co\_switch} in my prior
description of Listing~\ref{lst:isolating-key}, I will focus here on describing
the \texttt{co\_rspec} structure, as well as its mutators and accessors.
%
\texttt{co\_rspec} describes the resources that the calling, owner, codomain
exports to a peer codomain; when the peer accesses the resource, the peer's
coprocess either proxies the operation to the owner's coprocess, or replicates
the resource, depending on policy.
%
In the case of file resources, \texttt{rspec} essentially specifies a union
mount for the peer codomain, with some files and resources belonging to the
owner domain.
%
The \texttt{rspec} parameter of \texttt{co\_attach} specifies the initial
export policy; \texttt{co\_getrspec} may latter refine this policy (where
the \texttt{fd} parameter is the descriptor for the peer codomain).


I implement the API entirely on top of the coprocess API of
Listing~\ref{lst:coproc-api}; in particular, \texttt{co\_attach},
\texttt{co\_getrspec} and \texttt{co\_setrspec} invoke \texttt{coproc\_call},
and \texttt{co\_switch} invokes \texttt{coproc\_raise}.
%
Auxiliary functions like \texttt{co\_pinmem} used in
Listing~\ref{lst:isolating-key}, and analogous functions for pinning other
resource types, are implemented on top of \texttt{co\_setrspec}.

% XXX: compare to 9p protocol: http://man.cat-v.org/plan_9/5/intro
\begin{lstlisting}[
    frame=single,
    caption={Codomain API},
    captionpos=b,
    label={lst:codomain-api},
]
int co_attach(char *url, struct co_rspec *rspec)
int co_switch(int fd)
int co_getrspec(int fd, struct co_rspec *rspec)
int co_setrspec(int fd, struct co_rspec *rspec)
\end{lstlisting}

% TODO: describe rspec further
%\begin{lstlisting}[
%    frame=single,
%    caption={Codomain API},
%    captionpos=b,
%    label={lst:rspec},
%]
%struct co_rspec {
%    TODO
%};
%\end{lstlisting}
%

%%
%In the \texttt{load\_key} function of Listing~\ref{lst:isolating-key}, the
%application calls \texttt{read\_file} on line 7,
%which opens a file, reads in the contents, and then closes the file.
%%
%Suppose \texttt{domain\_pub} first tested if \texttt{path} existed;
%would that test succeed?  
%%
%Beyond this simple example, suppose that \texttt{domain\_priv} created a
%file; would \texttt{domain\_pub} be able to view it? 
%%
%
%% XXX: you need the process on B to call co_setrspec() before execve() to
%% specify the resources.
%
%%
%%In Listing~\ref{lst:isolating-key}, the domains do not need to share the filesystem:
%%\texttt{domain\_pub} and \texttt{domain\_priv} have completely separate
%%filesystems, and path names may even clash between the two.
%
%
%Similar issues exist for file descriptors.
%%
%For instance, in the example, \texttt{log} writes the log statements to a log
%descriptor.
%%
%This descriptor could represent a terminal, a file, or a socket.
%%
%We may want the write to proxy the call back to \texttt{domain\_pub} (which
%would be necessary in the socket case), or to perform the write locally, as by
%``migrating" the underlying resource from \texttt{domain\_pub} to
%\texttt{domain\_priv} (which may be more appropriate for the terminal case).
%%
%In other words, \texttt{rspec} not only needs to say which resources
%are shared, but also how they are shared.
%


\parhead{Distributed Shared and Cloaked Memory}
%
%% why codomains need DSM
For multi-threaded and multi-process applications, we must consider how the
system maintains consistency of memory layout and coherency of shared memory
among threads operating concurrently on multiple codomains.
%
This problem generaally necessitates some form of distributed shared memory.


%% DSM definition and how DSM fits into codomain design
% TODO: cite for DSM protocol papers
\emph{Distributed shared memory} (DSM) provides distributed processes with a
shared address space accessible through the conventional memory access protocols
(in contrast to message passing).
%
DSM protocols differ with regard to data granularity, synchronization,
and consistency models.
%
A common paradigm is the use of  write-invalidations: each domain
write-protects shared pages; when a domain tries to write to such a page, a
protection fault occurs.
%
In the case of codomains, the coprocess would notify peer domains that the
page is locked for writing, and, then make the page writeable to its process.


%% codomain-specific needs/concerns wrt to DSM
In addition to normal DSM behavior, the coprocess's DSM implementation must
also handle cloaked pages.
%
When a domain accesses a cloaked page, the result is a fault to the process's
coprocess.
%
The coprocess either treats the fault as a segmentation fault (likely
terminating the process), or as a page fault.
%
In the latter case, the coprocess handles the page fault by moving execution to
the domain of the page owner, as if the application implicitly called
\texttt{co\_switch}.
%
The application dictates fault semantics via \texttt{rspec} when attaching to
the codomain.


\parhead{Checkpoint/Restore}
%
\emph{Checkpoint/restore} (C/R) is the ability to snapshot the state of an
application and then later restore it to a running state, possibly
on a different system.
%
Two conventional uses for C/R are live migration of containers,
and the incremental snapshotting of an application, as for recovery
after a crash, outage, or malware infection.
%
% TODO: cite sprite/dmtcp/popcorn-linux/criu
Several research and commercial systems implement C/R, but CRIU, which manages
the operation from userspace, is the \emph{de facto} standard on Linux.
%
For the purposes of querying the kernel for a process's state, and later
passing that state back to the kernel when restoring the process,
CRIU makes heavy use of the \texttt{/proc} file system, netlink sockets,
system calls, and \texttt{ptrace}, the latter of which injects parasite code
to dump any remaining information.


There are several issue with composing these existing C/R systems, and CRIU in
particular, with codomains, which reflect a mismatch in their use cases, design
decisions, and assumptions.
%
The major points of incongruity are (1) the coarse-grained C/R of a process vs.
the fine-grained C/R of a thread; (2) infrequent vs. frequent C/R operations
(and the application's associated senstivity to the latency of the operation);
(3) the inverse nature of checkpointing with restoring vs. C/R in the presence
of cloaked data and resources; and (4) the use of C/R to move a whole system,
rather than using C/R to distribute a single system.
%
I merely bring up these issues to note that the codomain design does not
necessarily entail an implementation that bundles existing functionality, and
that an implementation might instead add kernel functionality such that the
coprocess can pull process state from the process descriptors (as returned by
\texttt{coproc\_create}).



\parhead{Parallel Execution}
% A computational modelis a conceptual view of the types of operations availableto a program.
%
%
When developing a new distributed, or, specifically, federated, application
with codomains, it is useful to have some notion of \emph{parallel
execution}---that is, a single-instruction, multiple-data computational model.
%
In a single-process, single-host setting, pthreads are the mechanism for
parallel execution; in a distributed setting, a framework such as MPI
may be used to develop a monolithic program that then executes a parallel
computation as a distributed system.
%
I ask whether codomains compose with pthreads to achieve a distributed,
parallel programming model similar to MPI.  \footnote{A related question is
whether codomains can augment MPI; I leave this as interesting future work.
}


For such computations, maintaining the memory and fileystem consistency across
codomains may not be a concern; it may be more natural for threads running in
separate codomains to have their own private address space and file system that
a master codomain has initialized.
%
When the codomain thread exits, it merely needs to return a value to some
master codomain, rather than overlay shared pages that contain the return
value.
%
% TODO: probably add arguments to co\_switch.
%
Moreover, the return value itself might need to be sealed (encrypted) to a
particular domain, such as to an enclave domain that then securely aggregates
the return values of all the codomains.


I sketch a design for how this might work in Listing~\ref{lst:lwc-parallel}.
%
The design relies on lightweight-contexts~\cite{lwcs}, which is an
OS-abstraction that allows a process to have multiple contexts (a collection of
resources that includes an address space, credentials, and file descriptor table),
and to switch in a coroutine-like fashion between these contexts over the
process's evolution.
%

%A simple, perhaps naive approach, would be that the private domains encrpyt the
%output using the public key of the enclave's domain.
%%
%This then brings up the question of how domains know of the existence of other
%domains; in particular, must ``capabilities" for other domains be passed in the
%\texttt{rspec}.


\begin{lstlisting}[
    frame=single,
    label={lst:lwc-parallel},
    numbers=left,
    numberstyle=\tiny,
    xleftmargin=2em,
    framexleftmargin=1.5em,
    caption={Combining codomains with light-weight contexts for parallel computation},
    captionpos=b,
]
int snapfd;

thr_func(worker_fd) {
    main_fd = co_switch(domain_fd)
    val = lwcswitch(snapfd)
    co_switch(main_fd);
    return val
}

main() {
    enclave_fd = co_attach()

    snapfd = lwccreate()
    if (snapfd != -1) {
        open("data.dat");
        val = do_work()
        encrypt_to_enclave(val)
        lwcswitchdicard(val);
    } 

    for 1 to N:
        pthread_create(thr_func, worker_fd)
            
    vals  = join_all_threads()
     
    main_fd = co_switch(enclave_fd)
    sum = secure_sum(vals)
    co_switch(main_fd)
}
\end{lstlisting}


\subsection{Enclaves as Codomains}
\label{sec:enclaves-as-codomains}

There are multiple challenges with migrating execution into an enclave; we
distill these challenges down to two problems: maintaing memory coherence with
peer codomains, and supporting dynamic attestation.


Memory coherence between a non-enclave codomain and enclave-codomain is
complicated due the differences in memory layout, specifically with regards to
the heap and thread context structures.
%
Additionally, lazy migration and DSM protocols must address the limitation that
all enclave memory must be commited at the time of enclave initialization, and
that the protection attributes of these memory pages cannot be changed during
enclave execution.
%
SGX2 overcomes some of these restrictions by permitting increased dynamic memory
management within an enclave, but at the expense of greater enclave
implementation complexity.
%
%Regardless...

With SGX, an enclave packaging step produces a measurement of the enclave image by
emulating the measurement tasks that the Intel hardware will perform when
loading the enclave.
%
With codomains, however, it is not immediately clear what parts of the
application constitute an enclave image.
%
This issue is, in part, bypassed by having the enclaved code simply be a loader
program that dynamically loads the relevant portions of the application, but
given that the executable pages could comprise only a small part of the
application, and that the initial state of the data pages is generally unknown,
it's not immediately clear what meaningful attestation the enclave could
provide a remote party.


\subsection{Data-Directed Switching}
\label{sec:data-directed-switching}

In Listing~\ref{lst:isolating-key}, partitioning the application simply
involved wrapping functions that access private data with calls to
\texttt{co\_switch}.
%
Consider the case where a party's private data cannot be encapsulated in a
functional interface.
%
My approach is to run the process under a \emph{dynamic binary
instrumentation} (DBI) framework.
%
DBI frameworks consist of an emulator that instruments and dispatches the
application's code, allowing the emulator to regain control at the end of each
basic block.
%
I provide instrumentation code that tracks the propagation of the sensitive
data over the course of the computation; as sensitive data taints other data,
the instrumented instructions invoke \texttt{co\_pinmem} on the associated
data's pages.


With this  method, I still assume that sensitive data is programmatically
introduced (as through \texttt{struct co\_rspec}), and that a coprocess
implicitly invokes \texttt{co\_switch} when a domain faults accessing cloaked
data.
%
However, it is not entirely obvious how the process, once migrated to the data
owning domain and running under a DBI framework, safely invokes
\emph{co\_switch} to switch back to the original faulting domain.
%
In general, such migration conditions are application-specific.
%
One application could simply wait until the process similarly faults on
cloaked data; another could add instrumetation that invokes
\texttt{co\_switch} after so many instructionrs have executed sequentially over
non-sensitive; and yet another could wait for the next programmatic instance of
\texttt{co\_switch}.


Composing codomains with a taint-tracking DBI framework is also potentially
beneficial in two other respects: (1) as a ``safety belt" for programs
that may inadvertentally leak sensitive data, and (2) as method for
partitioning black-box, trusted applications, that require a party's sensitive
input, such that the sensitive input does not leak to other parties.
%
With black-box partitioning, tainted data may have to declassified for liveness
concerns; for instanace, taint-tracking instrumention would mark a signature as
tainted, even though it is not semantically sensitive.
%
Declassificaiton requires hooking at least the epilogues of such functions.
%
In essence, this results in \emph{half-wrapping}, whereby a domain could be
migrated to at any point based on faults, but has well defined exit points and
exit conditions.







\subsection{Potentional Issues}

\parhead{Deadlock}
%
Applications running over codomains are susceptible to a form of deadlock
whereby, during the course of a thread's execution, the thread reaches an
instruction that accesses two pieces of data, each pinned to a separate domain.
%
In some cases, this may be indicative of a programming error, as by failing to
partition the application so that the computation occurs in a secure enclave,
if available.
%
A plausible, inadvertent, deadlock scenario is a server that supports multiple
tenants and uses a global data structure to manage the (pinned) keys across all
tenants.
%
In such cases, the application may need to be patched to correct the offending
memory layout.
%
In the general case, the problem is one of secure multi-party computation, and
an interesting area of future work is for the system to emit garbled circuits
when it detects such events.


\parhead{Private Code}
%
In my design of codomains, I focus on cloaking sensitive data, but
proprieatary software also necessitates cloacking sensitive code.
%
Naively, this scenario reduces to pinning private code pages to
the owning domain, and restricting domain switches to only
non-private points in the application's execution.
%
However, this restriction alone is insufficient, as data written by private
code pages should, likewise, be marked private, as sharing such data pages
could reveal aspects of the private code.
%
This scenario requires an alternative form of taint-analysis that additionally
applies taint to instructions and propagates taint from instructions to
operands, rather than solely propagating taint from one memory operand to
another.


\parhead{False sharing}
%
A disadvantage of the integration between virtual memory and DSM is that the
unit of access and locking are constrained to be a page.
%
If the application allocates multiple data structures on the same page, then
this constraint can lead to \emph{false sharing}, wherein distinct private data
structures appear shared due to colocation on the same page.
%
A similar phenomenon occurs when applying taint tags at page granularity.


\parhead{Inadvertent data leakage}
%
Although codomains present an interface for partitioning an application across
trust boundaries, partitionioning alone does not prevent private data leakage.
%
For instance, local results and parameters from a federated learning
application, may reveal information about the private data samples.
%
Thus, orthogonal to codomains, the application may additionally require
methods for achieving differential privacy, such as by adding a carefully
chosen amount of noise to the local results.


\parhead{Integrity}
%
% TODO: quote the work that criticizes keyless-ssl as just being an encryption
% oracle.



% TODO: for MEM_PIN_SWITCH, what is the resource_spec?

% TODO: how is the pinned domain marked in the page table?  (a unique
% memory protection key):.

% TODO: what does the target argumet to switch() look like?  In other words,
% how are domains represented form the application's point of view?
%
%
% TODO: what would happen if the filesystem needed to be shared?
%
% TODO: what happens if pinned data is written to a descriptor/file?



% TODO: try to translate switch() into a "remote" lwc:
%  
%   fd = lwccreate(resource_spec)
%   ret = lwcswitch(fd)
%   if (parent):
%       switch
%       migrate
%   else:
%       

%   Antoher issue is that reads and writes to the file must subsequently be
%   kept in sync with any toher processes using that file on src. 
%    
% - What happens if dst tries to read/write a descriptor that was opened on src?
%
%   Similar situation where the file either needs to migrate to dst or the
%   calls proxied.
%
%   You can think of migrate() of being like a fork, and specifing which file
%   descriptors are kept open and which are closed across the join.  Or similar
%   to the mem_pin, src would pin the desripotrs, saying that access should
%   either fault, migrate back, or be proxied.
%
%   For the crypto and federated examples, there's no need for sharing
%   filedescriptors and files.
% 
%   - suppose domian_priv forgot to close the file descriptor as part of
%     read_file -- would that descriptor then be open in domain_priv?
